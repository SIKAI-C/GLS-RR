# Programming.
# Interpolation of noisy data: comparison of Gaussian linear system
# approach and ridge regression using polynomial basis functions.


############################
## Gaussian Linear System ##
############################

# define the function and some invariant number
fa = function(t){sin(t)}                   # 0 <= t <= 2*pi
fb = function(t){sin(10*t)}                # 0 <= t <= 2*pi
N = 30                                     # the size of observations
D = 1000                                   # the number of the sub-intervals
t = 2*pi*(1/(2*D)+seq(0,1,by=1/D)[1:1000]) # choose the middle point for each sub-interval
x_a = fa(t)                                # about sin(t)
x_b = fb(t)                                # about sin(10t)
var_err = 0.1                             # set the variance of the noise
var_y_inv = diag(1,N,N)*(1/var_err)        # inverse of the covariance matrix of y

# sample set and selection matrix
row_gen = function(k){
  # generate a row in selection matrix
  r = rep(0,D)
  r[k] = 1
  return(r)
}

# make the zero-one selection matrix
selection = function(){
  sample_set = sample(c(1:D),N,replace=F) # generate a random sample 
  A = matrix(,nrow=N,ncol=D)
  for (i in c(1:N)){
    A[i,] = row_gen(sample_set[i])
  }
  return(A)
}


# the noisy data
simulation = function(task="a"){
  A = selection()
  err = rnorm(N,0,sqrt(var_err))
  if (task == "a"){
    y = A%*%x_a + err
  }
  else{
    y = A%*%x_b + err
  }
  return(list("y"=y,"A"=A))
}

# L matrix
m = c(1:D)
n = c(1:(D-2))
L1 = (-1)*(outer(n,m,"-")==0)
L2 = 2*(outer(n,m,"-")==-1)
L3 = (-1)*(outer(n,m,"-")==-2)
L = 0.5*(L1+L2+L3)

# calculate 3 times for a specific lamda
calculate = function(lamda,task="a"){
  sim_result = simulation(task)
  y = sim_result$y
  A = sim_result$A
  var_x_inv = lamda*(t(L)%*%L)
  var_final = solve(var_x_inv+t(A)%*%var_y_inv%*%A) 
  miu_final = var_final%*%(t(A)%*%var_y_inv%*%y)
  upper_bound = c()
  lower_bound = c()
  for (i in c(1:length(miu_final))){
    upper_bound[i] = miu_final[i] + 1.96*sqrt(var_final[i,i])
    lower_bound[i] = miu_final[i] - 1.96*sqrt(var_final[i,i])
  }
  return(list("miu"=miu_final,"up"=upper_bound,"low"=lower_bound,"A"=A,"y"=y))
}

# show the result for a specific lamda
show_single = function(lamda,task="a"){
  expr = fa
  if (task == "b"){expr = fb}
  result1 = calculate(lamda,task)
  result2 = calculate(lamda,task)
  result3 = calculate(lamda,task)
  o1 = result1$miu; o2 = result2$miu; o3 = result3$miu
  p1 = result1$up;  p2 = result2$up;  p3 = result3$up
  q1 = result1$low; q2 = result2$low; q3 = result3$low
  A1 = result1$A;   A2 = result2$A;   A3 = result3$A
  y1 = result1$y;   y2 = result2$y;   y3 = result3$y
  curve(expr,0,2*pi,add=F,col="black",xlab="",ylab="",ylim=c(-4,4))
  points(A1%*%t,y1,pch=4,col="black")
  points(A2%*%t,y2,pch=4,col="black")
  points(A3%*%t,y3,pch=4,col="black")
  lines(t,o1,col="blue")
  lines(t,o2,col="brown")
  lines(t,o3,col="red")
  curve(expr,0,2*pi,add=F,col="black",xlab="",ylab="",ylim=c(-40,40))
  points(A1%*%t,y1,pch=4,col="black")
  points(A2%*%t,y2,pch=4,col="black")
  points(A3%*%t,y3,pch=4,col="black")
  lines(t,o1,col="blue")
  lines(t,o2,col="brown")
  lines(t,o3,col="red")
  polygon(c(t,rev(t)),c(p1,q1),col=adjustcolor("blue",alpha.f=0.10),border=NA)
}


print("lamda = 30, sin(t)")
show_single(30,"a")
print("lamda = 5, sin(t)")
show_single(5,"a")
print("lamda = 30, sin(10t)")
show_single(30,"b")
print("lamda = 5, sin(10t)")
show_single(5,"b")




######################
## Ridge Regression ##
######################

# set the parameters and observations
n = 30
D = 1000
lamda_r = c(0.01,0.1,1,10)
degree = c(2,4,6,8)
fa = function(t){sin(t)}  
fb = function(t){sin(10*t)} 
t = 2*pi*(1/(2*D)+seq(0,1,by=1/D)[1:1000])
x = sample(t,n,replace=F)
err = rnorm(n,0,sqrt(0.1))
y_a = fa(x)+err
y_b = fb(x)+err

# generate the inputs matrix for the specific degree = d
generate_X = function(degree,a=x){
  X = matrix(,ncol=degree,nrow=length(a))
  for (i in c(1:degree)){
    X[,i] = a**i
  }
  X = cbind(1,X)
  return(X)
}


# find the regression parameters for given data, degree and lamda
find_coef = function(degree,lamda,y){
  X = generate_X(degree)
  a = dim(t(X)%*%X)[1]
  b = t(X)%*%y
  c = chol(t(X)%*%X+lamda*diag(1,a))
  mid_sol = solve(t(c),b)
  sol = solve(c,mid_sol)
  return(list("coefs" =  sol, "X" = X))
}

# return the different polynomial models according to different values of degree
expr = function(degree,x,coefs){
  if (degree == 2){
    return(coefs[1] + coefs[2]*x + coefs[3]*x^2)
  }
  if (degree == 4){
    return(coefs[1] + coefs[2]*x + coefs[3]*x^2 + coefs[4]*x^3 + coefs[5]*x^4)
  }
  if (degree == 6){
    return(coefs[1] + coefs[2]*x + coefs[3]*x^2 + coefs[4]*x^3 + coefs[5]*x^4
           + coefs[6]*x^5 + coefs[7]*x^6)
  }
  if (degree == 8){
    return(coefs[1] + coefs[2]*x + coefs[3]*x^2 + coefs[4]*x^3 + coefs[5]*x^4
           + coefs[6]*x^5 + coefs[7]*x^6 + coefs[8]*x^7 + coefs[9]*x^8)
  }
}

# draw error bars
errorBar = function(X,degree,lamda,y_regression){
  t1 = t[seq(1,by=20,length.out=50)]
  y1 = y_regression[seq(1,by=20,length.out=50)]
  P = generate_X(degree,t1)
  c = P%*%solve(t(X)%*%X+lamda*diag(1,degree+1))%*%t(X)
  covar_matrix = c%*%t(c)*0.1
  sd = sqrt(diag(covar_matrix))
  sd
  arrows(x0=t1,y0=y1-sd,x1=t1,y1=y1+sd,col="orange",code=3,angle=90,length=0.01)
}

# show the visualization of the ridge regression with specific lamda and degree
showRidge = function(degree,lamda,task="a"){
  y = y_a; f = fa
  if (task == "b"){y = y_b; f = fb}
  result = find_coef(degree,lamda,y)
  X = result$X; coefs = result$coefs
  y_regression = expr(degree,t,coefs)
  curve(f,0,2*pi,col="black",xlab="",ylab="",ylim=c(-1.5,1.5))
  lines(t,y_regression,type="l",col="blue")
  points(x,y,pch=4,col="red")
  errorBar(X,degree,lamda,y_regression)
}

showRidge(4,1)

for (task in c("a","b")){
  for (j in lamda_r){
    for (i in degree){
      cat("lamda = ",j ,"degree = ", i,"task = ",task,"\n")
      showRidge(i,j,task)
    }
  }
}





